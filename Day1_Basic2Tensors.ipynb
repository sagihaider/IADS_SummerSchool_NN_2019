{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day1_Basic2Tensors.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagihaider/IADS_SummerSchool_NN_2019/blob/master/Day1_Basic2Tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe48_GXQdGRT",
        "colab_type": "text"
      },
      "source": [
        "Data representations for neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2QB_eEvdP3y",
        "colab_type": "text"
      },
      "source": [
        "**Scalars (0D tensors): **\n",
        "\n",
        "A tensor that contains only one number is called a scalar (or scalar tensor, or 0-dimensional\n",
        "tensor, or 0D tensor)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjmTgzY5dLNo",
        "colab_type": "code",
        "outputId": "ab845b5d-6a3f-4a66-edcc-3ecab56f53fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "x = np.array(12)\n",
        "print(x)\n",
        "x.ndim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T2YpDA9d9Zi",
        "colab_type": "text"
      },
      "source": [
        "**Vectors (1D tensors):**\n",
        "\n",
        "An array of numbers is called a vector, or 1D tensor. A 1D tensor is said to have exactly\n",
        "one axis. Following is a Numpy vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBRj0hQveJ-7",
        "colab_type": "code",
        "outputId": "267b7534-5292-4297-f632-d998b635278c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = np.array([12, 3, 6, 14])\n",
        "print(x)\n",
        "x.ndim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12  3  6 14]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlnAYHuuemxC",
        "colab_type": "text"
      },
      "source": [
        "**Matrices (2D tensors)**\n",
        "\n",
        "An array of vectors is a matrix, or 2D tensor. A matrix has two axes (often referred to\n",
        "rows and columns). You can visually interpret a matrix as a rectangular grid of numbers.\n",
        "This is a Numpy matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3BW9-9_eo79",
        "colab_type": "code",
        "outputId": "0d9fb556-9164-4d83-a9c6-cf4657f8b00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "x = np.array([[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]])\n",
        "\n",
        "print(x)\n",
        "x.ndim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 5 78  2 34  0]\n",
            " [ 6 79  3 35  1]\n",
            " [ 7 80  4 36  2]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci-GwqfQfAhu",
        "colab_type": "text"
      },
      "source": [
        "**3D tensors and higher-dimensional tensors**:\n",
        "\n",
        "If you pack such matrices in a new array, you obtain a 3D tensor, which you can visually\n",
        "interpret as a cube of numbers. Following is a Numpy 3D tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNUEuX2ufDXe",
        "colab_type": "code",
        "outputId": "42b4ad49-275a-4c36-9c9d-57f7604bc333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "x = np.array([[[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]]])\n",
        "\n",
        "print(x)\n",
        "x.ndim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]\n",
            "\n",
            " [[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]\n",
            "\n",
            " [[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv9M2itEfaE8",
        "colab_type": "text"
      },
      "source": [
        "**A tensor is defined by three key attributes:**\n",
        "\n",
        "* **Number of axes (rank)** :  For instance, a 3D tensor has three axes, and a matrix has\n",
        "two axes. This is also called the tensor’s ndim in Python libraries such as Numpy.\n",
        "\n",
        "* **Shape** : This is a tuple of integers that describes how many dimensions the tensor\n",
        "has along each axis. For instance, the previous matrix example has shape\n",
        "(3, 5), and the 3D tensor example has shape (3, 3, 5). A vector has a shape\n",
        "with a single element, such as (5,), whereas a scalar has an empty shape, ().\n",
        "\n",
        "* **Data type** : (usually called dtype in Python libraries)—This is the type of the data\n",
        "contained in the tensor; for instance, a tensor’s type could be float32, uint8,\n",
        "float64, and so on. On rare occasions, you may see a char tensor. Note that\n",
        "string tensors don’t exist in Numpy (or in most other libraries), because tensors\n",
        "live in preallocated, contiguous memory segments: and strings, being variable\n",
        "length, would preclude the use of this implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcUCmhj1lF0H",
        "colab_type": "text"
      },
      "source": [
        "Let's look at example from MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpwIg8jdfqku",
        "colab_type": "code",
        "outputId": "cd1e9dc4-b222-4734-d4c7-cc1e6102012c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.ndim)\n",
        "\n",
        "print(train_images.shape)\n",
        "\n",
        "print(train_images.dtype)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "3\n",
            "(60000, 28, 28)\n",
            "uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw4zNm2tlkb4",
        "colab_type": "text"
      },
      "source": [
        "Let's display the 5th digit of the train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1ryHMMSlqM0",
        "colab_type": "code",
        "outputId": "9529f50f-c9c4-43e8-9917-fc0f6b209165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "digit = train_images[4]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEX4gaAIPxAU4QeCIvxAUP8HF8NDxhA0MHUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1rzALMzmKRZ",
        "colab_type": "text"
      },
      "source": [
        "Manipulating tensors in Numpy: Slicing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJZOvrjqmMzG",
        "colab_type": "code",
        "outputId": "fd6e915a-186e-402d-b580-2a24bead81cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "my_slice = train_images[10:100]\n",
        "print(my_slice.shape)\n",
        "\n",
        "my_slice = train_images[10:100, :, :]\n",
        "print(my_slice.shape)\n",
        "\n",
        "my_slice = train_images[10:100, 0:28, 0:28]\n",
        "print(my_slice.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90, 28, 28)\n",
            "(90, 28, 28)\n",
            "(90, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5KEO-xm0T53",
        "colab_type": "text"
      },
      "source": [
        "The notion of data batches\n",
        "\n",
        "Deep-learning models don’t process an entire dataset at once; rather,\n",
        "they break the data into small batches. Concretely, here’s one batch of our MNIST digits,\n",
        "with batch size of 128:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTJv3iE90YYT",
        "colab_type": "code",
        "outputId": "7dac7051-56e4-48a9-8144-d9551b0db757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch = train_images[:128]\n",
        "batch.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgaIj--40_F6",
        "colab_type": "text"
      },
      "source": [
        "And here’s the next batch:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USKWVomG1Ap0",
        "colab_type": "code",
        "outputId": "6dd34f52-183a-4dd5-c142-7b8e0bca826b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch = train_images[128:256]\n",
        "batch.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q9ES2F31H22",
        "colab_type": "text"
      },
      "source": [
        "And the nth batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VOJ81lG1Iy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n=5\n",
        "batch = train_images[128 * n:128 * (n + 1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZWwspse1UFH",
        "colab_type": "text"
      },
      "source": [
        "When considering such a batch tensor, the first axis (axis 0) is called the batch axis or\n",
        "batch dimension. This is a term you’ll frequently encounter when using Keras and other\n",
        "deep-learning libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tXAsnVa1ZfE",
        "colab_type": "text"
      },
      "source": [
        "**Real-world examples of data tensors**\n",
        "\n",
        "Let’s make data tensors more concrete with a few examples similar to what you’ll\n",
        "encounter later. The data you’ll manipulate will almost always fall into one of the following\n",
        "categories:\n",
        "\n",
        "1. Vector data—2D tensors of shape *(samples, features)*\n",
        "\n",
        "2. Timeseries data or sequence data—3D tensors of shape *(samples, timesteps, features)*\n",
        "\n",
        "3. Images—4D tensors of shape *(samples, height, width, channels)* or *(samples, channels, height, width)* \n",
        "\n",
        "4. Video—5D tensors of shape *(samples, frames, height, width, channels)* or *(samples, frames, channels, height, width)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxrqObOF1jq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}